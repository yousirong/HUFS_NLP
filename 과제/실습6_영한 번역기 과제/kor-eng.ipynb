{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_qNSzzyaCbD"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jmjh290raIky"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Neural machine translation with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOpGoE2T-YXS"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/nmt_with_attention.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiwtNgENbx2g"
   },
   "source": [
    "This notebook trains a sequence to sequence (seq2seq) model for Spanish to English translation. This is an advanced example that assumes some knowledge of sequence to sequence models.\n",
    "\n",
    "After training the model in this notebook, you will be able to input a Spanish sentence, such as *\"¿todavia estan en casa?\"*, and return the English translation: *\"are you still at home?\"*\n",
    "\n",
    "The translation quality is reasonable for a toy example, but the generated attention plot is perhaps more interesting. This shows which parts of the input sentence has the model's attention while translating:\n",
    "\n",
    "<img src=\"https://tensorflow.org/images/spanish-english.png\" alt=\"spanish-english attention plot\">\n",
    "\n",
    "Note: This example takes approximately 10 minutes to run on a single P100 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1617072334691,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "gKAXMZ3VBYW3",
    "outputId": "f85b8ea2-c204-47e1-b812-87bc0d121808"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 739,
     "status": "ok",
     "timestamp": 1617087721003,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "tnxXKDjq3jEL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfodePkj3jEa"
   },
   "source": [
    "## Download and prepare the dataset\n",
    "\n",
    "We'll use a language dataset provided by http://www.manythings.org/anki/. This dataset contains language translation pairs in the format:\n",
    "\n",
    "```\n",
    "May I borrow this book?\t¿Puedo tomar prestado este libro?\n",
    "```\n",
    "\n",
    "There are a variety of languages available, but we'll use the English-Spanish dataset. For convenience, we've hosted a copy of this dataset on Google Cloud, but you can also download your own copy. After downloading the dataset, here are the steps we'll take to prepare the data:\n",
    "\n",
    "1. Add a *start* and *end* token to each sentence.\n",
    "2. Clean the sentences by removing special characters.\n",
    "3. Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
    "4. Pad each sentence to a maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1617087728623,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "kRVATYOgJs1b"
   },
   "outputs": [],
   "source": [
    "# Download the file\n",
    "#path_to_zip = tf.keras.utils.get_file(\n",
    "#    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "#    extract=True)\n",
    "\n",
    "path_to_file = \"./구어체(1).txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1617090790953,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "rd0jw-eC3jEh"
   },
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "  #w = unicode_to_ascii(w.lower().strip())\n",
    "  w = w.lower().strip()\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^0-9a-zA-Z가-힣?.!,¿]+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1617090795769,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "opI2GzOt479E",
    "outputId": "bb51eeaf-a2b3-43f3-84b0-59a5a58df820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1617090800014,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "OHn4Dct23jEm"
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3022,
     "status": "ok",
     "timestamp": 1617090808098,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "cTbSbBz55QtF",
    "outputId": "1032147e-e194-4c7a-99c0-8d34d6407cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> when you make an order , he cooks on the steel pan right away . <end>\n",
      "<start> 네가 가서 주문하면 즉석에서 철판에 요리를 해줘 . <end>\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "ko, en = create_dataset(path_to_file, None)\n",
    "print(en[80000])\n",
    "print(ko[80000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1617090814837,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "bIOn8RCNDJXG"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1617090818696,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "eAY9k49G3jE_"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOi42V79Ydlr"
   },
   "source": [
    "### Limit the size of the dataset to experiment faster (optional)\n",
    "\n",
    "Training on the complete dataset of >100,000 sentences will take a long time. To train faster, we can limit the size of the dataset to 30,000 sentences (of course, translation quality degrades with less data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7594,
     "status": "ok",
     "timestamp": 1617090829399,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "cnxC7q-j3jFD",
    "outputId": "a5022a22-6538-44f3-9bc6-fef369becacd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 100000 100000\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 100000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "print(num_examples, len(input_tensor), len(target_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1617090842650,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "4QILQkOs3jFG",
    "outputId": "b28f4525-6d5d-46d8-8eea-3eb6822bdc6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000 20000 20000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1617090852000,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "lJPmLZGMeD5q"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 605,
     "status": "ok",
     "timestamp": 1617090856506,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "VXukARTDd7MT",
    "outputId": "3b95debf-4490-47bc-a700-f376ab7cde23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "14 ----> it\n",
      "195 ----> d\n",
      "29 ----> be\n",
      "101 ----> very\n",
      "65 ----> good\n",
      "32 ----> if\n",
      "7 ----> you\n",
      "39 ----> like\n",
      "23 ----> me\n",
      "3565 ----> continually\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "11 ----> 당신이\n",
      "191 ----> 계속\n",
      "98 ----> 나를\n",
      "6434 ----> 좋아하면\n",
      "318 ----> 좋겠어요\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ----> <start>\n",
      "14 ----> it\n",
      "64 ----> would\n",
      "29 ----> be\n",
      "2295 ----> appreciated\n",
      "32 ----> if\n",
      "7 ----> you\n",
      "854 ----> deliver\n",
      "40 ----> this\n",
      "386 ----> message\n",
      "6 ----> to\n",
      "5 ----> the\n",
      "376 ----> customer\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "1 ----> <start>\n",
      "11 ----> 당신이\n",
      "1549 ----> 고객에게\n",
      "138 ----> 그렇게\n",
      "3262 ----> 이야기해\n",
      "730 ----> 주면\n",
      "12616 ----> 고맙겠어요\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "convert(inp_lang, input_tensor_train[1000])\n",
    "\n",
    "convert(targ_lang, target_tensor_train[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1617090872625,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "TqHsArVZ3jFS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26261 121248\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print(vocab_inp_size, vocab_tar_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 931,
     "status": "ok",
     "timestamp": 1617090878041,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "qc6-NK1GtWQt",
    "outputId": "b14695a0-f662-4181-95b4-6a5880138480"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 48]), TensorShape([64, 32]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNfHIF71ulLu"
   },
   "source": [
    "## Write the encoder and decoder model\n",
    "\n",
    "Implement an encoder-decoder model with attention which you can read about in the TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt). This example uses a more recent set of APIs. This notebook implements the [attention equations](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism) from the seq2seq tutorial. The following diagram shows that each input words is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence. The below picture and formulas are an example of attention mechanism from [Luong's paper](https://arxiv.org/abs/1508.04025v5). \n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
    "\n",
    "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*.\n",
    "\n",
    "Here are the equations that are implemented:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
    "\n",
    "This tutorial uses [Bahdanau attention](https://arxiv.org/pdf/1409.0473.pdf) for the encoder. Let's decide on notation before writing the simplified form:\n",
    "\n",
    "* FC = Fully connected (dense) layer\n",
    "* EO = Encoder output\n",
    "* H = hidden state\n",
    "* X = input to the decoder\n",
    "\n",
    "And the pseudo-code:\n",
    "\n",
    "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
    "* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, hidden_size)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
    "* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
    "* `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "* `merged vector = concat(embedding output, context vector)`\n",
    "* This merged vector is then given to the GRU\n",
    "\n",
    "The shapes of all the vectors at each step have been specified in the comments in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1617090887410,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1617090891701,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "60gSVh05Jl6l",
    "outputId": "0e2529f0-2358-42eb-f54d-34011fdf7111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 48, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  6722816   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3938304   \n",
      "=================================================================\n",
      "Total params: 10,661,120\n",
      "Trainable params: 10,661,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1617090897194,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "umohpBN2OM94"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1617090901002,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "k534zTHiDjQU",
    "outputId": "56380cfa-118c-495f-9692-25ebdecacee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1617090905388,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "yJ_B3mhW3jFk"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1512,
     "status": "ok",
     "timestamp": 1617090910621,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "P5UY8wko3jFp",
    "outputId": "34620369-9f22-4567-f0ea-22c03968e0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 121248)\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  31039488  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  multiple                  7084032   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  124279200 \n",
      "_________________________________________________________________\n",
      "bahdanau_attention_1 (Bahdan multiple                  2100225   \n",
      "=================================================================\n",
      "Total params: 164,502,945\n",
      "Trainable params: 164,502,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ch_71VbIRfK"
   },
   "source": [
    "## Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1298,
     "status": "ok",
     "timestamp": 1617090914520,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "WmTHr5iV3jFr"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMVWzzsfNl4e"
   },
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 829,
     "status": "ok",
     "timestamp": 1617090918369,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "Zj8bXQTgNwrF"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpObfY22IddU"
   },
   "source": [
    "## Training\n",
    "\n",
    "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
    "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
    "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
    "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "5. Use *teacher forcing* to decide the next input to the decoder.\n",
    "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
    "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1617090923498,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "sC9ArXSsVfqn"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 916
    },
    "executionInfo": {
     "elapsed": 50935,
     "status": "error",
     "timestamp": 1617091109495,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "ddefjBMa3jF0",
    "outputId": "cdb85fc2-0420-47fd-af90-b7997247c690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.1435\n",
      "Epoch 1 Batch 100 Loss 2.3967\n",
      "Epoch 1 Batch 200 Loss 2.2448\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-bb8b18a677ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU3Ce8M6I3rz"
   },
   "source": [
    "## Translate\n",
    "\n",
    "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token*.\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1617090579703,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "EbQpyYs13jF_"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1617090584790,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "s5hQWlbN3jGF"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1617090588228,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "sl9zUHzg3jGI"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n250XbnjOaqP"
   },
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1769,
     "status": "ok",
     "timestamp": 1617090593237,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "UJpT9D5_OgP6",
    "outputId": "1422d9be-6220-431a-81a0-3d92d49cc91a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0b0d2bf510>"
      ]
     },
     "execution_count": 160,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1671,
     "status": "ok",
     "timestamp": 1617090627213,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "WrAM0FDomq3E",
    "outputId": "4b4f909b-ef84-46f7-84e5-f0e400128ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> it is hard to save time <end>\n",
      "Predicted translation: 그것은 이야기하자면 먹는 것이 좋습니다 . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44536 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44163 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51008 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50556 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44592 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54616 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51088 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47732 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47673 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45716 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51339 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49845 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45768 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45796 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44536 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44163 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51008 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50556 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44592 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54616 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51088 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47732 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47673 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45716 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51339 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49845 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45768 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45796 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('it is hard to save time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1034,
     "status": "ok",
     "timestamp": 1617090663992,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "zSx2iM36EZQZ",
    "outputId": "bcbf6322-b9ca-457c-ab3e-f52df7cd5e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> you are pretty small <end>\n",
      "Predicted translation: 당신은 지금 매우 좋습니다 . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45817 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49888 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51008 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51648 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44552 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47588 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50864 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51339 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49845 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45768 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45796 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45817 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49888 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51008 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51648 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44552 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47588 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50864 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51339 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49845 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45768 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45796 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('you are pretty small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769
    },
    "executionInfo": {
     "elapsed": 1003,
     "status": "ok",
     "timestamp": 1617090703393,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "A3LLCx3ZE0Ls",
    "outputId": "573f6443-7575-4b02-d9ce-e0938141e8e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> why does he have long hair ? <end>\n",
      "Predicted translation: 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 왜 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50780 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50780 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('why does he have long hair?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1633,
     "status": "ok",
     "timestamp": 1617090739118,
     "user": {
      "displayName": "‍김낙현[교수 / 컴퓨터공학부]",
      "photoUrl": "",
      "userId": "03321232562404235167"
     },
     "user_tz": -540
    },
    "id": "DUQVLVqUE1YW",
    "outputId": "aba3c28d-2f6c-4e9b-8281-37bbc60ef8bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> when do we take dinner ? <end>\n",
      "Predicted translation: 우리 저녁 식사 게 언제입니까 ? <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50864 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47532 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51200 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45377 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49885 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49324 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44172 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50616 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51228 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51077 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45768 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44620 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50864 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47532 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51200 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45377 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49885 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49324 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44172 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50616 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51228 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51077 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45768 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44620 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJwCAYAAAAjo60MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZSnCV3f+8+X6Z5phmEGBWRRQWQRAWWARrYICDEQnHBCoiiyCmHuIVExOcQTVAJGQUlwwXhzMxMVRZAJEA1GWUSFQBQul0EOuwgii2yDrAPMyvf+8fxaqmpqNpju51tdr9c5fabq+dXy7Wd+1b93PWt1dwAAWN+11h4AAICFMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYDVBVt66qP62qb1t7FgBgPcJshkcnuW+Sx648BwCwonIT83VVVSX5mySvTPJPkty0uy9ddSgAYBW2mK3vvkmum+RHk1yS5EGrTgMArEaYre/RSV7c3V9Ics7mfQBgH7Irc0VVdZ0kH0nyPd392qo6Pcnrktykuz+97nQAwLFmi9m6/nmST3T3a5Oku9+c5K+S/MCqUwHAcaaqrlNVj6qq09ae5YoIs3U9Msnzdix7XpLHHPtRAOC49tAkz8ny2juWXZkrqapvTPK+JN/a3X+1Zfk3ZDlL83bd/e6VxgPYM6rq5CQXdPeX1p6FuarqVUlulOQL3X147XkujzADYM+qqhOSXJDkjt39jrXnYaaq+qYk707yHUlen+TOU58vdmWuqKputrmO2a6PHet5APaazXUf35/kxLVnYbRHJnnt5ljul2bwFRCE2brel+SGOxdW1fU3jwFw5X4myc9X1Q3WHoSxHpXktzdvPz/Jwy9vw8ja7MpcUVV9KcmNuvu8HctvnuQd3X2ddSYD2Duq6q1JbpHkYJIPJfn81se7+9vXmIsZquqeSf4oyY27+/yqOjHJR5N8f3e/ct3pLuvA2gPsR1X1K5s3O8nPVdUXtjx8QpZ94G8+5oMB7E0vXnsARnt0kpd09/lJ0t0XVdULs1wBYVyY2WK2gs2ZIUlynywXlL1oy8MXZTkr81lbz9YEAK6eqjopy9axh3X3y7cs/wdJXpFlr9X5a823G2G2ks2+7RcmeWx3f27teQD2sqo6lOSMJLdMclZ3f7qqbpnkU939yXWnYy2b4w4flOR5Oy+nUlWPSPLH3f3RVYa7HMJsJU7xBrhmVNWtkvxxklOSXC/Jbbr7r6vqWUmu193/YtUB4WpwjNlKuvvSqnKK9xZV9f1J7p/k67LjjOHufvAqQwF7wS9nObj7CUm23mf497Nc6R32DGG2riOneD+iuz+x9jBrqqr/lOTHkrwqyYeznBgBcFXcM8ndN7/wbl3+gSQ3XWck1lRV78tVfB3p7m8+yuNcLcJsXU/Kcor331bVfj/F+1FZDs50dhXwlTi4y7KbJfnMsR6EEX51y9unJPk3Sd6Q5YS7JLlHlisg/MIxnutKCbN1iZAvu1ZcIgT4yvxRlhfex23e76o6NclPJ/nD1aZiNd3998FVVb+Z5Jnd/YytH1NVT05y+2M82pVy8D8jVNXTk1zc3U9bexZgb6mqm2Y5DCJJvjnJXyS5VZKPJbn3zot4s79U1Wez3BvzPTuW3yrJm7r71HUm250tZkxxvSQ/WFXfneQtSS7e+mB3/+gqUwHjdfeHq+r0JA9LcucsW+DPTvL87v7iqsMxweeT3DfJe3Ysv2+SL+z84LXZYraizW0hfjLLPyY3y45jJLr7hDXmWsOWi+7uprv7fsdsGACOG1X141lOtntOktdvFt89yx0Bntbdz1xrtt0IsxVV1TOTfH+Sn0vyS0l+Ksk3JfmBJE/p7rPWmw6YqqpulOSRWS6m+pTu/kRV3SvJh7v7fetOt46q+oYk987ul9v5xVWGYoyqemiSJyb51s2idyZ5dne/cL2pdifMVrQ5nfcJ3f3yqvpcktO7+71V9YQk9+/u7115xGNuc5XmWyZ5c3dfuPY8ME1V3SXJnyR5X5YDl2+7uZjq07JcWPUH15xvDVX18CS/keSSJOdl+2USetrlEOCKXOvKP4Sj6EZJjlz1//wsx1klycuT/KNVJlpJVV23ql6U5ONJ/jzJ12+W/9fNCw6weFaW3/TvlGTrLy+vSHKvdUZa3X/IctmDU7v7m7r7Flv+iDL+XlVdr6q+duuftWfaSZita+vFD9+T5AGbt++RZL8dsPrMLOviztn+d/+DJA9ZZSKY6S5JfmuX5R/J8svefnSjJL/W3ZeuPQjzVNXNq+plVfXFJH+XZavqeUk+sfnvKM7KXNfvZbkF0euTPDvJC6rq8Vm2Fv2nNQdbwYOTPKS731xVW3dDvDPL6e/A4otJvmaX5bfNssV5P3ppkrsl+eu1B2Gk52TZI/W47IE7ywizFXX3k7e8/eKq+mCWXRHv7u4/WG+yVXxNlt9kdrpuEr8Fw5e9JMlTq+r7Nu93VX1Tlq3O/2OtoVb2yiTPrKrbJ3lrLnu5nd9dZSqm+I4st+x629qDXBUO/l9RVd07yZ939yU7lh9Ics/ufs06kx17VfXqJP+zu395cyLEt3f3+6rq/0ly8+5+0LoTwgybK9q/NMm3J7lOko9m2ZX3Z0ke1N2fv4JPPy5V1Zeu4OHeT5ce4rKq6q1JHtPd5649y1UhzFZUVZcmuUl3f3zH8usn+fh++sekqu6Z5eDlc5I8IsmvZTnj7DuyXLn7TSuOB+NU1f3y5Yupvqm7/7iqDnb3xVfyqbCvbH5W/l2Sf7nz6v8TCbMVbX7Lu9HO24VU1W2SvHHabSKOtqr6tiw3dr9LNi82We5v9tZVB4NBqupnuvspuyw/McmLu/vBK4wFY232wpyU5IQsZzJv20s17bXWMWYrqKrf37zZSZ5XVVtPeT8hyR2yXDJiX9kE2KPXngOGe1xVndfdv3JkQVUdTPK7Sb5hvbHWVVV3y3Iy1W4XmHVLt/3th9ce4OoQZus4cpB7JflUtl8e4qIk/yfJfzvWQ02wuRnxbv+w2pW5z1XV4SwXH/6D7v58VV0nyYU7j9HcB/5xkldV1d919/M3W8p+L0uU7ctbl1XVk5L8xyyXHdp51p3dQvtcd+92eZmx7MpcUVU9Ncmz9uPBujtV1Z2SPC/LKf+142EH7+5jm9sPvSTL8Yad5NabK92fleSC7n7iqgOuoKq+M8s1/h6b5IeyRNn9u3u3M5uPe5sz2p/Z3b+69izMtJduY+YCs+v6mWzZWlZVN66qf7E5EH6/OTvJB5N8Z5brlt1iyx/XMdvffinJx5JcP8kXtix/UfbZHTKO6O7XJvnBJC/Ict3D++3XKNs4cqYqXMbmNmZ/meThWa5lduSYsu9O8vS15ro8dmWu6w+z3H7p2VV1SpI3Zjn9/ZSqelx3P3fV6Y6t2yW5U3e/e+1Bpqiqk7L8Q3K7LFuK3p7kBfvwHqL3z7I16FNV2zamvjfJzdYZ6djaclzqTp9I8vkkv3lk3ezTg/9fkOSBSf7L2oMw0pHbmD11cyLAEa/IssV5FGG2rsNJfnzz9j9L8tksW4genuXsxP0UZm9NcuMkwixJVd0uycuSnJZl3STJ45P8dFU9sLvfudpwx961sxx7udMNk1xwjGdZy+VtDXvFMZ1irg9m+dm4V5K35LIXmP3FVaZiirtk2VK208jbmDnGbEWb+3bdprs/WFXPS/L+7v7JqrpZknd293VWHvGo2nHz2NOTPCPJT2X3K3d/8hiOtrqqemWW3XaP7O7PbpadmuU4vJO6+wFX9PnHk6r6gyRv6e6fOHLx4Sz3mX1hkku7+6GrDsjqquqKjhFqNzLf36rqY1kuvnzu5t+QO26OU31gkrO7e9SWd2G2oqr6yyRPTfK/kvxNku/r7ldX1elJXtndN1xzvqNtcx23rU/AI/updi7bdwf/V9UXkty1u9++Y/m3JXn98R7tW222Hv7vJG9Ocp8sB73fPsvWxHt193tXHA8YrqrOzrJH5vuy7P7/9iyvMy9J8qfd/a9XHO8y7Mpc1y8m+e0k5yd5f5Ijt2C6d768++p49l1rDzDYBVluurvTadk/u++SJN39jk2QPiHLxSEPZTnw///u7o+sOtxKquqHkjwsyzF2J259zNYhuIwnZTk55LwkJ2e5JNWNslwv9KdWnGtXtpitbHO2yM2ybCE7f7Pse5J8urv/bNXhjqGq+qMkr978ecM+vDbVNlX1W0numuW4stdvFt8jyVlZ1s+4A1aPls1z41VZtpp5blT92yRPzvJc+NdZDni/VZZf6J7V3T+74njHTFX9SpInb65p9ytX9LEuMEuy+23MVh5pV8JsJVV1WpYbdb92l8fuleQd3f2pYz/ZOqrqZ5LcN0uMXJzkddnHoVZV10vyW0n+SZJLN4tPyLLp/Ye6+9NrzXasVdXPZtmF6bmRpKreneQnuvvFO46XeUqSm3X341ce8ZioqlcleUh3f3rz9uXqblvn96m9+ForzFZSVdfNckbIA7ZuGauqOyZ5Q5Kv7+5PrDXfWqrq2knumSXS7pvkblkuIjrqXmbHSlXdKsm3bt595164Ae/R4rmx2Bx/eNvu/kBVfTzJP+ruN2+eK2/o7q+9ki8B+8ZefK11jNlKuvtzVfWSJI9KsnWX5SOTvGLaE+UYOjXJDbLclulGWW42e+6qEx0jVfUbV/IhD9lyrarHHv2Jxtm3z40dPpplPXwgy7Gp98hyYsStso9uP3QVfl6O6O7e7VIJ7AN78bVWmK3ruUleUFU/0t0XVdW1slzNe0/dcPWaUFX/JctWkJsn+X+zHE/0+CxnIO6XC6ruPAv33km+lC+fCHKHLMdGvCb7iOfGZfxpkgcneVOSX0/yS1X10CzHzrxwzcGOMT8vXFV76rXWrswVbZ4cH0zyI939u1X13VmuYH2T7r74ij/7+LK5dMZ5SX41y4VVz+19/OSsqicnuVOW48k+v1l2nSwvxG/t7nG3ETlaPDe2q6pbJPnb7r5o8/73J7lXlht4v3Q/7u728/JlVXVGlq2n53T3R9eeZ4K99lorzFZWVc9M8i3d/U+r6rlJPtfd/2rtuY61qrplvnzs0H2SXDfLKc2vSvLq7n7TasOtoKo+kuU2RO/Ysfz2Sf6ku2+8zmTHnufGdlV1aZYXlI/vWH79JB/fb9f8S/y8HFFV/y7LPZg/nmWP2D/s7v1w6aUrtZdea+3KXN9zk5y7udr/Q7LcF3Df2Vwk9L1ZfsNNVd02y+2qfj7L2Yj77cXmlCQ3TfKOHctvkuU6PPuG58ZlVHY/luyU7LNr3G3h52XxL5M8rrufW1U/keSVVfWoJO9K8uEsu38PdvcH1hxyJXvmtVaYray7315Vb0vy/CQf6u43rD3TGjabmg9nuejsfbPsmjmU5eDuV6822Hr+R5LnbK5ZdeQ6ZndP8swkv7vaVCvw3FhsuVZXJ/m5zdmZR5yQ5DuynASwH/l5WXxtNsfUdfczNj87L9s8dtcsrzO3yf77ZWZPvdYKsxmem+SXk/zk2oOs6NNJTspyQPOrs6yP/3PkeJF96AlJfiHJbyY5uFl2SZatRk9aaaa1eG4svm3z38pyCZWtN3a/KMv6edaxHmoIPy+Ldye5XZZb/KW7f7aqfj3LlsN3ZjkzcT9tQdxpT7zWOsZsgM3NvH8kyVn79WDNqnpA9ueL7RXaHMB8y827792P68dzY7uqek6SJx65uT1ftt9/Xqrqh5N8V3f/87VnmWivvNYKMwCAIa619gAAACyEGQDAEMJsiKo6c+0ZJrE+trM+trM+trM+trM+trM+tpu+PoTZHKOfKCuwPrazPrazPrazPrazPrazPrYbvT6EGQDAEPv+rMwT66Q+lOusPUYuzoU5mJPWHmMM62O7KeujTjx45R90DFx06Rdz4gnXXnuM5IQZ1+m86JLP58QD6/87dutbf3LtEZIk5/3dpbnh9df/f/OuD+68z/o6Lr7w/Bw86ZS1x8i1Pv2FK/+gY+DiviAH69DaY+Rz/clPdPdlniT7/gKzh3Kd3K3G3pkBRjlw029ce4RRvnTa+jE0yctefs7aI4xyryf+X2uPMMp1/+dfrD3CKK+86Hfev9tyuzIBAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBAH1h7gqqiq+yQ5K8kFuzz8riS3SHLSLo+dnOR+3f2hozgeAMA1Yk+EWZJrJzmnu5+2dWFVHUry8iTd3afv/KSqOid75+8IAOxzdmUCAAwhzAAAhtiXu/mq6swkZybJoZy88jQAAIt9ucWsu8/u7sPdffjgrucMAAAce/syzAAAJhJmAABDCDMAgCGEGQDAEMIMAGAIYQYAMMReuY7ZZ5KcUVVn7PLYuUluXlVvvJzPvfDojQUAcM3ZE2HW3a9LcnjtOQAAjia7MgEAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAY4sDaAwB7xyUf+NDaI4xywmmnrj3CKG++8MK1Rxjl777vC2uPMMopL7po7RH2BFvMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwxIG1B7gqquo+Sc5KcsEuD78ryS2SnLTLYycnuV93f+gojgcAcI3YE2GW5NpJzunup21dWFWHkrw8SXf36Ts/qarOyd75OwIA+5xdmQAAQwgzAIAh9uVuvqo6M8mZSXIoJ688DQDAYl9uMevus7v7cHcfPrjrOQMAAMfevgwzAICJhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMsVeuY/aZJGdU1Rm7PHZukptX1Rsv53MvPHpjAQBcc/ZEmHX365IcXnsOAICjya5MAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIY4sPYAwN5RBw6uPcIoF97lVmuPMMoP/Pbt1h5hlIPn19ojjHLC9U5be4RZPrX7YlvMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwxIG1B7gqquo+Sc5KcsEuD78ryS2SnLTLYycnuV93f+gojgcAcI3YE2GW5NpJzunup21dWFWHkrw8SXf36Ts/qarOyd75OwIA+5xdmQAAQwgzAIAh9uVuvqo6M8mZSXIoJ688DQDAYl9uMevus7v7cHcfPrjrOQMAAMfevgwzAICJhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMsVeuY/aZJGdU1Rm7PHZukptX1Rsv53MvPHpjAQBcc/ZEmHX365IcXnsOAICjya5MAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIY4sPYAMNq1Tlh7AgbrE2rtEUa55W9+ZO0RRvnSKYfWHmGUi+/4zWuPMMurd19sixkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIY4sPYA14Squk+Ss5JcsMvD7+ruHzjGIwEAXG3HRZgluXaSc7r7aVsXVtWhJC9fZSIAgKvJrkwAgCGEGQDAEMfLrsyrparOTHJmkhzKyStPAwCw2JdbzLr77O4+3N2HD+aktccBAEiyT8MMAGAiYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDHC/XMftMkjOq6oxdHjv3WA8DAPCVOC7CrLtfl+Tw2nMAAHw17MoEABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYIgDaw8Ao33p0rUnGKX7S2uPMMqJr3rL2iOMcqnnB1fgwLWvvfYIe4ItZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGOLAV/sFquo+Sc5KcsEuD78ryS2SnLTLYycnuV+Shyd5ZJJLdpnt15L8ryQvS/KFXb7GZ7v73lX1e5vvs9OhJI/p7tdfhb8KAMCqvuowS3LtJOd099O2LqyqQ0lenqS7+/Sdn1RV52y+/9ck+eHufvWOxx+Y5O5JDib58+5+zC5f40hw3eRyvsfPZ4kzAIDx7MoEABjimthitudU1ZlJzkySQzl55WkAABb7cotZd5/d3Ye7+/DBXQ9/AwA49vZlmAEATCTMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwxDVxgdnPJDmjqs7Y5bFzk9y8qt54OZ97YZIPJXlWVe32+NlJvpjkDpfzNT68+e87r+B7vOhyJwcAGOSrDrPufl2Sw1/Fl/jVzZ8rcoVfv7t/6Kv4/gAAI9iVCQAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQB9YeANhDuteeYJS++KK1R4A9o88/f+0R9gRbzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMMRxFWZV9cNV9RdV9fmq+mBVPXntmQAArqoDaw9wDbt/kn+f5O1J7p3k16rq7d39++uOBQBw5Y6rMOvuh2x596+r6hlJbrXWPAAAV8dxFWZbVdVPJDmY5JxdHjszyZlJcignH+PJAAB2d1wdY3ZEVf1Ukh9L8t3d/eGdj3f32d19uLsPH8xJx35AAIBdHHdbzKrqpkn+Q5Lv6e43rz0PAMBVdTxuMbtJkkryzrUHAQC4Oo7HMHtnkrsmucwuTACAyY7HMLtDkuclueHagwAAXB3HY5idnORbspyRCQCwZxx3B/9396uzHGMGALCnHI9bzAAA9iRhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwxIG1B1jbabe/NA944WfXHmOMV9zh1LVHGKUO7Psfke3K73LbXKvWnmCUE254g7VHGOXSj5239ghMdtHui/0rCwAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEPsmTCrqidV1d+sPQcAwNGyZ8IMAOB4d42EWVWdWlXXuya+1tX4njesqkPH8nsCABxNX3GYVdUJVfWAqvqdJB9NcsfN8tOq6uyq+nhVfa6q/ndVHd7yeY+pqvOr6v5V9baq+nxVvaqqbrHj6/94VX1087HPTXLKjhEelOSjm+91r6/07wEAMMXVDrOqun1V/cckH0zy35N8PskDk7ymqirJHyb5+iRnJLlTktck+dOqusmWL3NSkicneWySeyS5XpL/uuV7PDTJzyZ5apI7J/nLJP9mxyjPT/KDSa6b5JVV9Z6q+vc7A+9y/g5nVtUbq+qN53/yoqu7CgAAjoqrFGZVdf2q+tGqOjfJXyS5bZInJrlxdz++u1/T3Z3ku5KcnuR7u/sN3f2e7n5Kkr9O8sgtX/JAkn+1+Zi3JHlWkvtuwi5JfizJb3X3Wd397u5+epI3bJ2puy/p7pd298OS3DjJMzbf/6+q6tVV9diq2rmV7cjnnt3dh7v78Clfe+JVWQUAAEfdVd1i9iNJnp3kgiS36e4Hd/eLuvuCHR93lyQnJzlvswvy/Ko6P8kdktxyy8dd2N1/ueX9Dyc5McnXbN7/1iSv2/G1d77/9wEGg+oAAARHSURBVLr7s939G939XUnumuRGSX49yfdexb8fAMDqDlzFjzs7ycVJHpXkbVX1e0l+O8mfdPelWz7uWkk+luQ7d/kan93y9iU7Hustn3+1VdVJWXadPiLLsWdvz7LV7SVfydcDAFjDVQqh7v5wdz+9u78lyT9Mcn6Sc5J8qKp+oapO33zom7JsrfrSZjfm1j8fvxpzvTPJ3Xcs2/Z+Lf5BVZ2V5eSD/5zkPUnu0t137u5nd/enrsb3BABY1dXeQtXdr+/uJyS5SZZdnLdJ8v9V1Xcm+eMkf5bkJVX1j6vqFlV1j6r66c3jV9Wzkzy6qh5fVbeuqicnuduOj3lEkj9KcmqShyX5xu7+t939tqv7dwIAmOCq7sq8jO6+MMmLk7y4qr4uyaXd3VX1oCxnVP63JF+XZdfmnyV57tX42v+9qr45ydOzHLP2+0l+McljtnzYn2Q5+eCzl/0KAAB7Ty0nU+5f33iH0/qJL9y513T/esUdTl17hFHqwFf8u8vxqdwsZJtr1ZV/zD5ywg1vsPYIo1z6sfPWHoHBXnnR75zb3Yd3LvevLADAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGAIYQYAMIQwAwAYQpgBAAwhzAAAhhBmAABDCDMAgCGEGQDAEMIMAGCIA2sPsLbPvP2EvOIOp649BkP1JZesPQLsGZd86G/XHgH2PFvMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGEGYAAEMIMwCAIYQZAMAQwgwAYAhhBgAwhDADABhCmAEADCHMAACGOLD2AGuoqjOTnJkkh3LyytMAACz25Raz7j67uw939+GDOWntcQAAkuzTMAMAmEiYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADCEMAMAGEKYAQAMIcwAAIYQZgAAQwgzAIAhhBkAwBDCDABgCGEGADBEdffaM6yqqs5L8v6150hygySfWHuIQayP7ayP7ayP7ayP7ayP7ayP7aasj5t39w13Ltz3YTZFVb2xuw+vPccU1sd21sd21sd21sd21sd21sd209eHXZkAAEMIMwCAIYTZHGevPcAw1sd21sd21sd21sd21sd21sd2o9eHY8wAAIawxQwAYAhhBgAwhDADABhCmAEADCHMAACG+P8BtNmT30q4rK0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wrong translation\n",
    "translate('when do we take dinner?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTe5P5ioMJwN"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "* [Download a different dataset](http://www.manythings.org/anki/) to experiment with translations, for example, English to German, or English to French.\n",
    "* Experiment with training on a larger dataset, or using more epochs\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kor-eng.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
