{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scikit_learn_feature_extraction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jg116907/NLPstudy/blob/master/Scikit_learn_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_ok5LXz4OdG",
        "colab_type": "text"
      },
      "source": [
        "# Scikit learn 특징 추출\n",
        "- 수치형 데이터가 아닐 경우에 특징 추출을 통해 수치화 필요\n",
        "- 텍스트 데이터 수치화에는 주로 세 가지 방법이 사용된다.\n",
        "  - CoutVectorizer : 각 텍스트에서 횟수를 기준으로 특징을 추출하는 방법\n",
        "  - TfidfVectorizer : TF-IDF라는 값을 사용해서 텍스트에서 특징을 추출\n",
        "  - HashingVectorizer : CountVectorizer와 동일한 기능이지만 Hash 함수를 사용, 효율이 더 좋다\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93QXIR4X9HGG",
        "colab_type": "text"
      },
      "source": [
        "## CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJT0qy3G3lUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhQw7-qU5_b_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지','내일 공부 해야겠다','점심 먹고 공부 해야지']\n",
        "count_vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFDq2WgN8Awy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "289899ff-e08f-4c6c-db9d-2ae9ea419622"
      },
      "source": [
        "count_vectorizer.fit(text_data)\n",
        "print(count_vectorizer.vocabulary_) # text data를 이용해서 단어 사전 생성"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er555ZBW8KdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23eba794-8075-40e4-b3fa-c5f9c26caef5"
      },
      "source": [
        "sentence = [text_data[0]] # ['나는 배가 고프다']\n",
        "print(count_vectorizer.transform(sentence).toarray()) # 해당 문장을 벡터화. 사전의 해당 하는 부분에 1씩 더해진다."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 1 0 0 0 1 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v58xO_Vy9Oy4",
        "colab_type": "text"
      },
      "source": [
        "## TfidfVectorizer\n",
        "- count는 단순 횟수만 잡기 때문에 조사, 지시대명사와 같이 특별한 의미 없이 자주 사용되는 단어가 높은 특징값을 가지게 된다. \n",
        "> tfidf는 이런 문제점을 해결 가능하다\n",
        "- TF : Term Frequency. 특정 단어가 하나의 데이터 안에서 등장하는 횟수\n",
        "- DF : Document Frequency. 문서 빈도 값. 특정 단어가 여러 데이터에 자주 등장하는지 알려주는 지표\n",
        "- IDF : Inverse Document Frequency. DF에 역수를 취함. 특정 단어가 여러 데이터에 자주 등장하지 않을수록 값이 커진다. \n",
        "- TF-IDF : 두 값을 곱한다. 어떤 단어가 해당 문서에 자주 등장하지만 다른 문서에는 많이 없는 단어일수록 높은 값을 가지게 된다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNZBu0hB8vkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l81_g-rAPE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지','내일 공부 해야겠다','점심 먹고 공부 해야지']\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4B2DFQSAfmb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fd7e8784-ef6f-4635-ce2d-aae7e8f49869"
      },
      "source": [
        "tfidf_vectorizer.fit(text_data)\n",
        "print(tfidf_vectorizer.vocabulary_) # 단어 사전 만들기\n",
        "\n",
        "sentence = [text_data[3]]#['점심 먹고 공부해야지']\n",
        "print(tfidf_vectorizer.transform(sentence).toarray()) # '공부','점심'은 0.4 정도의 값을 가지고, '먹고','해야지'는 0.5 정도의 값을 가진다. -> '먹고','해야지'가 다른 데이터에서 나오지 않았기 때문"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n",
            "[[0.         0.43779123 0.         0.         0.55528266 0.\n",
            "  0.         0.43779123 0.         0.55528266]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}