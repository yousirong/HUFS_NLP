{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_data_classification_eng_modeling_lgs",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jg116907/NLPstudy/blob/master/Text_data_classification_eng_modeling_lgs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZskxEanC33Ze",
        "colab_type": "text"
      },
      "source": [
        "# 모델링 소개\n",
        "  1. 로지스틱 회귀 모델\n",
        "    - 주로 이항 분류를 위해 사용됨\n",
        "    - TF-IDF와 word2vec을 이용한 벡터화를 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXLcnvj55QGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZlpyrX9Iht7",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF를 활용한 로지스틱 회귀 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zLRY_ob32R2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TF-IDF를 활용한 모델 구현\n",
        "train_data = pd.read_csv(\"train_clean.csv\",header=0)\n",
        "\n",
        "reviews = list(train_data[\"review\"])\n",
        "sentiments = list(train_data[\"sentiment\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKJXwYeC5_39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TF-IDF 벡터화\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df=0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3), max_features=5000)\n",
        "# analyzer -> word : 단어 하나 단위, char : 문자 하나 단위\n",
        "X = vectorizer.fit_transform(reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc_X9ZXL7XJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train/test set 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TEST_SPLIT = 0.2\n",
        "\n",
        "y = np.array(sentiments)\n",
        "\n",
        "X_train,X_eval,y_train,y_eval = train_test_split(X,y,test_size=TEST_SPLIT,random_state=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLDoNGUZ8cVW",
        "colab_type": "code",
        "outputId": "7b821b9b-9d16-4427-e965-4f4cd73dcb46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "# 모델 선언 및 학습\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lgs = LogisticRegression(class_weight='balanced') # 각 라벨에 대해 균형있게 학습\n",
        "lgs.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKBszAby87wx",
        "colab_type": "code",
        "outputId": "c67194c5-0fd8-42dd-b40e-87bedc758b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 검증 데이터로 성능 평가\n",
        "print(\"Accuracy : \", lgs.score(X_eval,y_eval))\n",
        "# 다양한 성능 평가 척도 : accuracy(정확도), precision(정밀도), recall(재현율), f1-score, auc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.8596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOOW-Fer9RNP",
        "colab_type": "code",
        "outputId": "d3cba086-4889-4de5-b9cb-8569ab14b279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test data 로드\n",
        "test_data = pd.read_csv(\"test_clean.csv\")\n",
        "\n",
        "# test data 벡터화\n",
        "testDataVecs = vectorizer.transform(test_data['review'])\n",
        "\n",
        "# 예측값\n",
        "test_predicted = lgs.predict(testDataVecs)\n",
        "print(test_predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyyma2WODML3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = list(test_data['id'])\n",
        "answer_dataset = pd.DataFrame({'id':ids, 'sentiment':test_predicted})\n",
        "answer_dataset.to_csv('lgs_tfidf_answer.csv',index=False,quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SYsucoGD7nG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# 자신의 kaggle account에서 api key 생성 후 kaggle.json 업로드\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYO5YgK1FIME",
        "colab_type": "code",
        "outputId": "d594f2f8-1152-42fd-85d6-35c11e6f0c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# 케글 제출\n",
        "!kaggle competitions submit -c word2vec-nlp-tutorial -f lgs_tfidf_answer.csv -m \"logistic regression with tf-idf vectorizer\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 276k/276k [00:03<00:00, 74.8kB/s]\n",
            "Successfully submitted to Bag of Words Meets Bags of Popcorn"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTdpom2nIoL8",
        "colab_type": "text"
      },
      "source": [
        "## Word2vec을 활용한 로지스틱 회귀 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQyG-xyhHLyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv(\"train_clean.csv\")\n",
        "\n",
        "reviews = list(train_data[\"review\"])\n",
        "sentiments = list(train_data[\"sentiment\"])\n",
        "\n",
        "sentences = []\n",
        "for review in reviews:\n",
        "  sentences.append(review.split()) # word2vec을 사용하기 위해서는 입력 값을 단어로 구분된 리스트로 만들어 줘야 함"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkBO-sczJuhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#학습 시 필요한 하이퍼 파라미터\n",
        "num_features = 300 # word vector의 feature 수\n",
        "min_word_count = 40 # 단어에 대한 최소 빈도 수\n",
        "num_workers = 4 # 프로세스 개수\n",
        "context = 10 # context window 크기\n",
        "downsampling = 1e-3 # 다운 샘플링 비율"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naOdil_dKgb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JgcoDi8K8fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습하는 과정에서 진행 상황을 확인하기 위한 logging\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvfePwExLhW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features, min_count=min_word_count, window=context, sample=downsampling)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM1beI48MBVW",
        "colab_type": "code",
        "outputId": "a65f360c-926f-46b8-d4ad-98f8b84ea5da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "# 모델 저장\n",
        "model_name = \"300features_40minwords_10context\"\n",
        "model.save(model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-21 07:23:30,950 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
            "2019-10-21 07:23:30,952 : INFO : not storing attribute vectors_norm\n",
            "2019-10-21 07:23:30,958 : INFO : not storing attribute cum_table\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2019-10-21 07:23:31,264 : INFO : saved 300features_40minwords_10context\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEimnYc1MxHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모든 벡터의 개수를 통일 시키기 위해 리뷰 하나당 벡터값을 평균낸다\n",
        "def get_features(words,model,num_features):\n",
        "  # 출력 벡터 초기화\n",
        "  feature_vector = np.zeros((num_features),dtype=np.float32)\n",
        "  \n",
        "  num_words = 0\n",
        "  # 어휘사전 준비\n",
        "  index2word_set = set(model.wv.index2word)\n",
        "  \n",
        "  for w in words:\n",
        "    if w in index2word_set:\n",
        "      num_words+=1\n",
        "      # 사전에 해당하는 단어에 대해 단어 벡터를 더함\n",
        "      feature_vector = np.add(feature_vector,model[w])\n",
        "  feature_vector = np.divide(feature_vector, num_words)\n",
        "  return feature_vector      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuDahsW5OxqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(reviews,model,num_features):\n",
        "  dataset = list()\n",
        "  for s in reviews:\n",
        "    dataset.append(get_features(s,model,num_features))\n",
        "  reviewFeatureVecs = np.stack(dataset)\n",
        "  \n",
        "  return reviewFeatureVecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qFUunBmPsbf",
        "colab_type": "code",
        "outputId": "b3674e5a-48ed-49df-d768-22eea6788572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "test_data_vecs = get_dataset(sentences,model,num_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIAuIORyQzxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train/test set 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = test_data_vecs\n",
        "y = np.array(sentiments)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TEST_SPLIT = 0.2\n",
        "\n",
        "X_train,X_eval,y_train,y_eval = train_test_split(X,y,test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKgg4y6eVg0Y",
        "colab_type": "code",
        "outputId": "5e9a66a0-0e03-496f-b773-b910cd260860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "# 모델 선언 및 학습\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lgs = LogisticRegression(class_weight='balanced')\n",
        "lgs.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvZZCgL3V3CH",
        "colab_type": "code",
        "outputId": "10d63f22-a46f-4f02-b7a8-8d98f1345942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 성능 평가\n",
        "print(\"Accuracy : \",lgs.score(X_eval,y_eval))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.8626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hql9vrHWKJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 제출\n",
        "test_data = pd.read_csv(\"test_clean.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbxlhnM7WTc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ids = list(test_data[\"id\"])\n",
        "test_reviews = list(test_data[\"review\"])\n",
        "test_sentences = []\n",
        "for review in test_reviews:\n",
        "  test_sentences.append(review.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpYZAX1iXTIM",
        "colab_type": "code",
        "outputId": "c3d006e0-0c49-4c32-8090-e43f60cca530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "test_data_vecs = get_dataset(test_sentences,model,num_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSqAAHxUXpXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predicted = lgs.predict(test_data_vecs)\n",
        "answer_dataset = pd.DataFrame({\"id\":ids,\"sentiment\":test_predicted})\n",
        "answer_dataset.to_csv(\"lgs_answer.csv\",index=False,quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmIzgMTNYmYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9fdcb4fc-a27e-4c98-bbcf-17fb5165a443"
      },
      "source": [
        "!kaggle competitions submit -c word2vec-nlp-tutorial -f lgs_answer.csv -m \"logistic regression with word2ved\""
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 276k/276k [00:03<00:00, 75.8kB/s]\n",
            "Successfully submitted to Bag of Words Meets Bags of Popcorn"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7quhERtaa3Nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}