{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chater7_3_Linear_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvI_ZpCKcqak"
      },
      "source": [
        "**3) 선형 회귀(Linear Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pzOMnI_csBg"
      },
      "source": [
        "5. 케라스로 구현하는 선형 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAEsaeLPTwBW"
      },
      "source": [
        "from tensorflow.keras.models import Sequential # 케라스의 Sequential() 을 임포트\n",
        "from tensorflow.keras.layers import Dense # 케라스의 Dense() 을 임포트\n",
        "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
        "import numpy as np # Numpu를 임포트\n",
        "\n",
        "X=np.array([1,2,3,4,5,6,7,8,9]) # 공부하는 시간\n",
        "y=np.array([11,22,33,44,53,66,77,87,95]) # 각 공부하는 시간에 맵핑되는 성적\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=1, activation='linear'))\n",
        "sgd=optimizers.SGD(lr=0.01) # 학습률(learning rate,lr)은 0.01 로 합니다\n",
        "model.compile(optimizer=sgd, loss='mse', metrics=['mse']) # sgd 는 경사 하강법을 의미. 손실함수(Loss function1)은 평균오차 mse 를 사용합니다.\n",
        "model.fit(X,y, batch_size=1, epochs=300, shuffle=False) # 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 300번 시도합니다\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Dwx5OYfm18"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, model.predict(X), 'b', X, y, 'k.')\n",
        "\n",
        "print(model.predict([9.5])) # 9시간 30분 공부\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}