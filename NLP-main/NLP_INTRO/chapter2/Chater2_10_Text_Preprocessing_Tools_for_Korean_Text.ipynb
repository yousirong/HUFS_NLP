{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chater2_10_Text_Preprocessing_Tools_for_Korean_Text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vm-vrtDnHzq"
      },
      "source": [
        "**10) 한국어 전처리 패키지(Text Preprocessing Tools for Korean Text)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut1dHWe0m_ht"
      },
      "source": [
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udc2-QwZq0x5"
      },
      "source": [
        "1. PyKoSpacing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCslk_2SqhOX"
      },
      "source": [
        "sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'\n",
        "print(sent)\n",
        "\n",
        "new_sent = sent.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
        "print(new_sent)\n",
        "print()\n",
        "\n",
        "from pykospacing import spacing\n",
        "\n",
        "kospacing_sent = spacing(new_sent)\n",
        "print('원문과 PyKoSpacing 비교 ------------------------------------------')\n",
        "print(sent)\n",
        "print(kospacing_sent)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcRwbUWjrW14"
      },
      "source": [
        "2. Py-Hanspell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OauNipd0rX-7"
      },
      "source": [
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcMfonXMrakn"
      },
      "source": [
        "from hanspell import  spell_checker\n",
        "\n",
        "sent = \"맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 \"\n",
        "print(sent)\n",
        "print()\n",
        "\n",
        "spelled_sent = spell_checker.check(sent)\n",
        "print(spelled_sent)\n",
        "print()\n",
        "\n",
        "hanspell_sent = spelled_sent.checked\n",
        "print('맞춤법 및 띄어쓰기 보정 -------------------------------')\n",
        "print(hanspell_sent)\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(new_sent)\n",
        "print()\n",
        "spelled_sent = spell_checker.check(new_sent)\n",
        "print(spelled_sent)\n",
        "print()\n",
        "\n",
        "hanspell_sent = spelled_sent.checked\n",
        "print('Py-Hanspell 과 PyKoSpacing 비교 ------------------------')\n",
        "print(hanspell_sent)\n",
        "print(kospacing_sent) # 앞서 사용한 kospacing 패키지에서 얻은 결과"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j483YjlIsiZP"
      },
      "source": [
        "3. SOYNLP를 이용한 단어 토큰화\n",
        "\n",
        "[soynlp - Github](https://github.com/lovit/soynlp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1tCpHgjsi-N"
      },
      "source": [
        "!pip3 install soynlp\n",
        "!pip3 install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9hKYnoAtIqb"
      },
      "source": [
        "1) 신조어 문제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dp1AkM_tHpJ"
      },
      "source": [
        "# import konlpy\n",
        "from konlpy.tag import Okt\n",
        "tokenizer = Okt()\n",
        "print(tokenizer.morphs('에이비식스 이대휘 1월 최애돌 기부 요정'))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAQRvyCzyfiG"
      },
      "source": [
        "2) 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6584WhzuTgE"
      },
      "source": [
        "import urllib.request\n",
        "from soynlp import DoublespaceLineCorpus\n",
        "from soynlp.word import WordExtractor\n",
        "\n",
        "# 학습에 필요한 한국어 문서 다운로드\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"2016-10-20.txt\")\n",
        "\n",
        "# 훈련 데이터를 다수의 문서로 분리\n",
        "corpus = DoublespaceLineCorpus(\"2016-10-20.txt\") \n",
        "print(len(corpus))\n",
        "\n",
        "# 상위 3개의 문서만 출력\n",
        "i=0\n",
        "for document in corpus:\n",
        "  if len(document) > 0:\n",
        "    print(document)\n",
        "    print()\n",
        "    i += 1\n",
        "  if i == 3:\n",
        "    break   \n",
        "\n",
        "print()\n",
        "\n",
        "word_extractor = WordExtractor()\n",
        "word_extractor.train(corpus)\n",
        "word_score_table = word_extractor.extract()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FaJHcqvyrK3"
      },
      "source": [
        "3) SOYNLP의 응집 확률(cohesion probability)\n",
        "\n",
        "  - 응집 확률은 내부 문자열(substring)이 얼마나 응집하여 자주 등장하는지를 판단하는 척도\n",
        "  - 이 값이 높을수록 전체 코퍼스에서 이 문자열 시퀀스는 하나의 단어로 등장할 가능성이 높습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp3iI7Fay5Qt"
      },
      "source": [
        "print(\"반포한         : \" + str(word_score_table[\"반포한\"].cohesion_forward))\n",
        "print(\"반포한강       : \" + str(word_score_table[\"반포한강\"].cohesion_forward))\n",
        "print(\"반포한강공     : \" + str(word_score_table[\"반포한강공\"].cohesion_forward))\n",
        "print(\"반포한강공원   : \" + str(word_score_table[\"반포한강공원\"].cohesion_forward))\n",
        "print(\"반포한강공원에 : \" + str(word_score_table[\"반포한강공원에\"].cohesion_forward))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8c99bmMyvgL"
      },
      "source": [
        "4) SOYNLP의 브랜칭 엔트로피(branching entropy)\n",
        "  -  주어진 문자열에서 얼마나 다음 문자가 등장할 수 있는지를 판단하는 척도\n",
        "  - 브랜칭 엔트로피의 값은 하나의 완성된 단어에 가까워질수록 문맥으로 인해 점점 정확히 예측할 수 있게 되면서 점점 줄어드는 양상을 보입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F92zDVGtDK7C"
      },
      "source": [
        "print(\"디         : \" + str(word_score_table[\"디\"].right_branching_entropy))\n",
        "print(\"디스       : \" + str(word_score_table[\"디스\"].right_branching_entropy))\n",
        "print(\"디스플     : \" + str(word_score_table[\"디스플\"].right_branching_entropy))\n",
        "print(\"디스플레   : \" + str(word_score_table[\"디스플레\"].right_branching_entropy))\n",
        "print(\"디스플레이 : \" + str(word_score_table[\"디스플레이\"].right_branching_entropy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZKuwSr7El6k"
      },
      "source": [
        "5) SOYNLP의 L tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrutGAtiFXYU"
      },
      "source": [
        "from soynlp.tokenizer import LTokenizer\n",
        "\n",
        "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
        "\n",
        "print(scores['국제사회'])\n",
        "print(scores['우리'])\n",
        "print(scores['노력'])\n",
        "print(scores['범죄'])\n",
        "print(scores['척결'])\n",
        "\n",
        "l_tokenizer = LTokenizer(scores=scores)\n",
        "l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH2N97W6EpIR"
      },
      "source": [
        "6) 최대 점수 토크나이저"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlHJFDNrHYu8"
      },
      "source": [
        "from soynlp.tokenizer import MaxScoreTokenizer\n",
        "\n",
        "print(scores['국'])\n",
        "print(scores['국제'])\n",
        "print(scores['국제사'])\n",
        "print(scores['국제사회'])\n",
        "print(scores['국제사회와'])\n",
        "print(scores['와'])\n",
        "print()\n",
        "print(scores['우'])\n",
        "print(scores['우리'])\n",
        "print(scores['우리의'])\n",
        "print(scores['의'])\n",
        "print()\n",
        "\n",
        "maxscore_tokenizer = MaxScoreTokenizer(scores=scores)\n",
        "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc9rXAL9IYrc"
      },
      "source": [
        "4. SOYNLP를 이용한 반복되는 문자 정제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdgp5vDpIfTb"
      },
      "source": [
        "from soynlp.normalizer import *\n",
        "\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠ', num_repeats=2))\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠ', num_repeats=2))\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠ', num_repeats=2))\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ', num_repeats=2))\n",
        "print()\n",
        "\n",
        "print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))\n",
        "print(repeat_normalize('와하하하하하하핫', num_repeats=2))\n",
        "print(repeat_normalize('와하하하하핫', num_repeats=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qzdcfuo_IdAz"
      },
      "source": [
        "5. Customized KoNLPy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt1vchGPJZrM"
      },
      "source": [
        "!pip3 install customized_konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsEGyXTtJBPt"
      },
      "source": [
        "# 형태소 분석 입력 : '은경이는 사무실로 갔습니다.'\n",
        "# 형태소 분석 결과 : ['은', '경이', '는', '사무실', '로', '갔습니다', '.']\n",
        "\n",
        "from ckonlpy.tag import Twitter\n",
        "\n",
        "twitter = Twitter()\n",
        "token = twitter.morphs('은경이는 사무실로 갔습니다.')\n",
        "print('사전추가 전 --------------------------------')\n",
        "print(token)\n",
        "print()\n",
        "\n",
        "twitter.add_dictionary('은경이', 'Noun')\n",
        "\n",
        "token = twitter.morphs('은경이는 사무실로 갔습니다.')\n",
        "print('사전추가 후 --------------------------------')\n",
        "print(token)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}