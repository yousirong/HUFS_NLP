{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chater4_4_TF_IDF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpaJ2_8NrhRP"
      },
      "source": [
        "**4) TF-IDF(Term Frequency-Inverse Document Frequency)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2F1lC5Brm4N"
      },
      "source": [
        "2. 파이썬으로 TF-IDF 직접 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO-3PXbCrcDV"
      },
      "source": [
        "import pandas as pd  # 데이터프레임 사용을 위해\n",
        "from math import log # IDF 계산을 위해\n",
        "\n",
        "docs = [\n",
        "  '먹고 싶은 사과',\n",
        "  '먹고 싶은 바나나',\n",
        "  '길고 노란 바나나 바나나',\n",
        "  '저는 과일이 좋아요'\n",
        "] \n",
        "\n",
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "print('정렬 전 --------------------------------------')\n",
        "print(vocab)\n",
        "print()\n",
        "vocab.sort()\n",
        "print('정렬 후 --------------------------------------')\n",
        "print(vocab)\n",
        "print()\n",
        "\n",
        "N = len(docs) # 총 문서의 수\n",
        "print('총 문서 수 ------------------------------------')\n",
        "print(N)\n",
        "print()\n",
        "\n",
        "# tf(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수.\n",
        "def tf(t, d): \n",
        "  return d.count(t)\n",
        "\n",
        "\n",
        "# df(t) : 특정 단어 t가 등장한 문서의 수.  \n",
        "def idf(t):\n",
        "  df = 0\n",
        "  for doc in docs:\n",
        "    df += t in doc\n",
        "  return log(N/(df + 1))\n",
        "\n",
        "# idf(d, t) : df(t)에 반비례하는 수.\n",
        "def tfidf(t, d):\n",
        "  return tf(t,d)*idf(t)\n",
        "\n",
        "\n",
        "result=[]\n",
        "for i in range(N): # 각 문서에 대해서 아래 명령을 수행\n",
        "  result.append([])\n",
        "  d = docs[i]\n",
        "  for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "    result[-1].append(tf(t,d))\n",
        "\n",
        "tf_ = pd.DataFrame(result, columns=vocab)\n",
        "print('DTM ----------------------------------------')    \n",
        "print(tf_)\n",
        "print()\n",
        "\n",
        "result=[]\n",
        "# for j in range(len(vocab)):\n",
        "#   t = vocab[j]\n",
        "#   result.append(idf(t))\n",
        "\n",
        "for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "    result.append(idf(t))\n",
        "\n",
        "idf_ = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\n",
        "print('IDF ----------------------------------------')    \n",
        "print(idf_)\n",
        "print()\n",
        "\n",
        "result = []\n",
        "for i in range(N):\n",
        "    result.append([])\n",
        "    d = docs[i]\n",
        "    for j in range(len(vocab)):\n",
        "        t = vocab[j]\n",
        "\n",
        "        result[-1].append(tfidf(t,d))\n",
        "\n",
        "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
        "print('TF-IDF --------------------------------------')    \n",
        "print(tfidf_)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upCc3O_JroWe"
      },
      "source": [
        "3. 사이킷런을 이용한 DTM과 TF-IDF 실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIvro3lVzTeT"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "    'you know I want your love',\n",
        "    'I like you',\n",
        "    'what should I do ',    \n",
        "]\n",
        "\n",
        "vector = CountVectorizer()\n",
        "print('DTM ----------------------------------------') \n",
        "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록한다.\n",
        "print()\n",
        "print('단어 정수 인덱싱 ----------------------------')\n",
        "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지를 보여준다.\n",
        "print()\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidfv = TfidfVectorizer().fit(corpus)\n",
        "print('TF-IDF --------------------------------------') \n",
        "print(tfidfv.transform(corpus).toarray())\n",
        "print()\n",
        "\n",
        "tfidf_ = pd.DataFrame(tfidfv.transform(corpus).toarray(), columns = tfidfv.vocabulary_.keys())\n",
        "print('TF-IDF --------------------------------------')    \n",
        "print(tfidf_)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}